# Multiple Directories Web scraping and Data Extraction

> :Note: **Notice:** It can be hard to navigate some of the files at this point as this is the first round over the code.
## 2nd Round will include:
- adding error handling logic to all the sites
- Cleanning file namings
- Cleaning data when possible

## Installation

1. Download nodejs from (https://nodejs.org/en/download)
2. Download / Clone the repository
3. run `npm install`.

## Important Subfolders
- [Client](client/): This folder contains the shared files from the client. 
- [Updated_Exel_Client](client/80%20Websites%20for%20Scraping%20-%20Ibrahim.xlsx): This is the exel file colored with the done / the notes on some of the sites and some of them containing techniques to extract
- `extracted_data` Within each of the folers. You can find the extracted data (Some sites have 2/ 3 ;layers of scrapping so you do not need to care about all the different files just look for the ones that contain the word `Data`)
-


## address are written in full in all cases as the formatiing of the addresses in the sites 

# Similar Sites, We can try sevel mechanisms / clean the code after extraction if possible
- **36, 39** 
- **41, 46, 47**
- **63** Added Regex for better parsing. 
- 

## Used `Load more` Logic  
- [27.theclimbingdirectory](27.theclimbingdirectory/)
- `35.`
- `77 , 79`
- `29`
- 


## Blogs, unstructured
- `10.airsoftpal` 
- `28.climbphilippines` got the data manually
- `56.parkrovers` got the data manually (can have a code written/ waste of time)


## License
This code is protected for the only purpose of `Ibrahim Gamal` use and his client after confirmation of payment. Thank you for understanding.